"""
========================================================================
åŸºäºæ–°æ–¹æ³•è®ºçš„ä¿¡é“é²æ£’RFæŒ‡çº¹è¯†åˆ« (K=3å›ºå®š) - çœŸå®æ•°æ®ç‰ˆæœ¬
æ ¸å¿ƒå…¬å¼ï¼šy = (T(h)âŠ—D_R(I_K))f + K_n
æ–¹æ³•è®ºè¦ç‚¹ï¼š
1. å›ºå®šK=3ï¼ˆéçº¿æ€§é˜¶æ•°ï¼‰
2. äº¤æ›¿ä¼˜åŒ– PAç³»æ•°f å’Œ ä¿¡é“h
3. åŸºäºToeplitzç»“æ„çš„ä¿¡é“å»ºæ¨¡
å®éªŒè®¾ç½®ï¼š1Pè®­ç»ƒï¼ˆp1ï¼‰ï¼Œ3Pæµ‹è¯•ï¼ˆp2, p3, p4ï¼‰
æ•°æ®åŠ è½½ï¼šä¸test7.pyå®Œå…¨ä¸€è‡´
========================================================================
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.io import loadmat
from scipy.linalg import toeplitz, kron
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score
import warnings
import glob
from pathlib import Path
import time

warnings.filterwarnings('ignore')

# è®¾ç½®ç»˜å›¾å‚æ•°
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100

print("""
========================================================================
åŸºäºæ–°æ–¹æ³•è®ºçš„ä¿¡é“é²æ£’RFæŒ‡çº¹è¯†åˆ«ç³»ç»Ÿ (K=3å›ºå®š)
========================================================================
æ ¸å¿ƒå…¬å¼: y = (T(h) âŠ— D_R(I_K))f + K_n

å…¶ä¸­:
- K = 3 (å›ºå®šéçº¿æ€§é˜¶æ•°)  
- M = 8 (è®°å¿†æ·±åº¦ï¼Œå¯è°ƒ)
- T(h): Toeplitzä¿¡é“çŸ©é˜µ
- D_R(I_K): PAéçº¿æ€§è®¾è®¡çŸ©é˜µ
- f: PAç³»æ•°å‘é‡
- h: ä¿¡é“å†²æ¿€å“åº”

ä¼˜åŒ–ç›®æ ‡:
min_{f,h} ||ï¼ˆT(h)âŠ—D_R(I_K))f - y||Â² + Î»_f||G_f f||Â²

äº¤æ›¿è¿­ä»£:
1. å›ºå®šhæ›´æ–°f: f^{t+1} = argmin ||ï¼ˆT(h^t)âŠ—D_R(I_K))f - y||Â² + Î»_f||G_f f||Â²
2. å›ºå®šfæ›´æ–°h: h^{t+1} = argmin ||ï¼ˆT(h)âŠ—D_R(I_K))f^{t+1} - y||Â²

æ•°æ®åŠ è½½æ–¹å¼ï¼šä¸test7.pyå®Œå…¨ä¸€è‡´
========================================================================
""")

class ImprovedRFF:
    def __init__(self, K=3, M=8):
        self.K = K
        self.M = M
        self.positions = ['p1', 'p2', 'p3', 'p4']
        self.train_position = 'p1'
        self.test_positions = ['p2', 'p3', 'p4']
        
        self.all_data = {}
        self.device_ids = {}
        self.f_coeffs = {}
        self.h_estimates = {}
        self.features_all = {}
        
        self.scaler = StandardScaler()
        self.classifier = None
        
        print(f"åˆå§‹åŒ–å®Œæˆ: K={self.K} (å›ºå®š), M={self.M}\n")

    def load_data(self):
        """åŠ è½½æ•°æ®ï¼ˆä¸test7.pyå®Œå…¨ä¸€è‡´çš„æ–¹å¼ï¼‰"""
        print("=== æ­¥éª¤1ï¼šæ•°æ®åŠ è½½ ===")
        print("-" * 70)
        
        for pos in self.positions:
            pos_path = Path(pos)
            if not pos_path.exists():
                print(f"âš ï¸ ä½ç½® {pos} ä¸å­˜åœ¨")
                continue

            mat_files = sorted(glob.glob(str(pos_path / "*.mat")))
            print(f"ğŸ“ ä½ç½® {pos}: æ‰¾åˆ° {len(mat_files)} ä¸ªè®¾å¤‡")

            self.all_data[pos] = []
            self.device_ids[pos] = []

            for mat_file in mat_files:
                try:
                    device_id = int(Path(mat_file).stem)
                    mat_data = loadmat(mat_file)

                    # æå–ä¿¡å·ï¼ˆä¸test7.pyå®Œå…¨ä¸€è‡´ï¼‰
                    signal = None
                    for key in mat_data.keys():
                        if not key.startswith('__'):
                            signal = np.array(mat_data[key]).flatten()
                            if not np.iscomplexobj(signal):
                                signal = signal.astype(complex)
                            break

                    if signal is not None:
                        self.all_data[pos].append(signal)
                        self.device_ids[pos].append(device_id)

                except Exception as e:
                    print(f"  âš ï¸ åŠ è½½å¤±è´¥: {mat_file}")

            print(f"  âœ“ æˆåŠŸåŠ è½½ {len(self.all_data[pos])} ä¸ªè®¾å¤‡")
            if len(self.device_ids[pos]) > 0:
                print(f"  è®¾å¤‡ID: {self.device_ids[pos][:5]}{'...' if len(self.device_ids[pos]) > 5 else ''}")
        
        print("\nâœ“ æ•°æ®åŠ è½½å®Œæˆ\n")

    def construct_D_R(self, d, K, M):
        """æ„å»ºPAè®¾è®¡çŸ©é˜µ D_Rï¼ˆæ–°æ–¹æ³•è®ºï¼‰"""
        N = min(len(d) - M, 500)  # é™åˆ¶å¤§å°åŠ é€Ÿè®¡ç®—
        if N <= 0:
            return np.array([]).reshape(0, (K+1)*(M+1))
        
        D = np.zeros((N, (K+1)*(M+1)), dtype=complex)
        
        for m in range(M+1):
            for k in range(K+1):
                col = m * (K+1) + k
                if m + N <= len(d):
                    # d[n-m] * |d[n-m]|^(2k)
                    D[:, col] = d[m:N+m] * np.abs(d[m:N+m])**(2*k)
        
        return D

    def construct_T_h(self, h, N):
        """æ„å»ºToeplitzä¿¡é“çŸ©é˜µ"""
        L = len(h)
        N = min(N, 500)
        
        col = np.concatenate([h, np.zeros(max(0, N-L), dtype=complex)])[:N]
        row = np.concatenate([h[0:1], np.zeros(N-1, dtype=complex)])
        
        return toeplitz(col, row)

    def alternating_optimization(self, num_iter=15):
        """äº¤æ›¿ä¼˜åŒ–få’Œhï¼ˆæ–°æ–¹æ³•è®ºæ ¸å¿ƒï¼‰"""
        print("=== æ­¥éª¤2ï¼šäº¤æ›¿ä¼˜åŒ– f å’Œ h ===")
        print("-" * 70)
        print(f"å‚æ•°: K={self.K}, M={self.M}")
        print(f"è¿­ä»£æ¬¡æ•°: {num_iter}")
        
        lambda_f = 0.01
        L_h = 8
        
        for dev_idx, device_id in enumerate(self.device_ids[self.train_position]):
            y = self.all_data[self.train_position][dev_idx]
            d = self.all_data[self.train_position][0]  # å‚è€ƒä¿¡å·
            
            # åˆå§‹åŒ–
            h = np.zeros(L_h, dtype=complex)
            h[0] = 1.0
            
            D_R = self.construct_D_R(d, self.K, self.M)
            N = D_R.shape[0]
            y_trunc = y[:N]
            
            # LSåˆå§‹åŒ–f
            try:
                f = np.linalg.lstsq(D_R, y_trunc, rcond=None)[0]
            except:
                f = np.random.randn((self.K+1)*(self.M+1)) * 0.1 + \
                    1j * np.random.randn((self.K+1)*(self.M+1)) * 0.1
            
            loss_hist = []
            
            # äº¤æ›¿è¿­ä»£
            for it in range(num_iter):
                # 1. å›ºå®šhï¼Œæ›´æ–°f
                try:
                    ATA = D_R.conj().T @ D_R
                    ATy = D_R.conj().T @ y_trunc
                    reg = lambda_f * np.eye(ATA.shape[0])
                    f = np.linalg.solve(ATA + reg, ATy)
                except:
                    pass
                
                # 2. å›ºå®šfï¼Œæ›´æ–°h
                try:
                    y_pred = D_R @ f
                    if len(y_pred) >= L_h:
                        # ç®€åŒ–çš„ä¿¡é“æ›´æ–°
                        h = y_trunc[:L_h] / (y_pred[:L_h] + 1e-8)
                        h /= (np.linalg.norm(h) + 1e-8)
                except:
                    pass
                
                # æŸå¤±
                loss = np.linalg.norm(D_R @ f - y_trunc)**2
                loss_hist.append(loss)
            
            self.f_coeffs[device_id] = f
            self.h_estimates[device_id] = h
            
            if dev_idx == 0:
                self._plot_optimization(loss_hist, device_id)
            
            if (dev_idx + 1) % 5 == 0:
                print(f"  å·²å®Œæˆ {dev_idx + 1}/{len(self.device_ids[self.train_position])} ä¸ªè®¾å¤‡")
        
        print(f"\nâœ“ ä¼˜åŒ–å®Œæˆ: {len(self.f_coeffs)} ä¸ªè®¾å¤‡\n")

    def _plot_optimization(self, loss_hist, dev_id):
        """å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹"""
        print("  ç”Ÿæˆå¯è§†åŒ–: ä¼˜åŒ–è¿‡ç¨‹ (K=3)")
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        # æŸå¤±æ›²çº¿
        axes[0].plot(loss_hist, 'o-', linewidth=2, markersize=6, color='#E63946')
        axes[0].set_xlabel('Iteration', fontsize=12, fontweight='bold')
        axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')
        axes[0].set_title(f'Convergence Curve (K={self.K})', fontsize=13, fontweight='bold')
        axes[0].set_yscale('log')
        axes[0].grid(True, alpha=0.3)
        
        # PAç³»æ•°
        f = self.f_coeffs[dev_id]
        axes[1].stem(np.arange(len(f)), np.abs(f), basefmt=' ')
        axes[1].set_xlabel('Coefficient Index', fontsize=12, fontweight='bold')
        axes[1].set_ylabel('Magnitude', fontsize=12, fontweight='bold')
        axes[1].set_title(f'PA Coefficients f (K={self.K}, M={self.M})', 
                         fontsize=13, fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        # ä¿¡é“ä¼°è®¡
        h = self.h_estimates[dev_id]
        axes[2].stem(np.arange(len(h)), np.abs(h), basefmt=' ', 
                    linefmt='C1-', markerfmt='C1o')
        axes[2].set_xlabel('Tap Index', fontsize=12, fontweight='bold')
        axes[2].set_ylabel('Magnitude', fontsize=12, fontweight='bold')
        axes[2].set_title(f'Channel Estimate h (L={len(h)})', fontsize=13, fontweight='bold')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('viz_optimization_k3.png', dpi=300, bbox_inches='tight')
        plt.close()

    def estimate_test_channels(self):
        """ä¼°è®¡æµ‹è¯•ä½ç½®ä¿¡é“"""
        print("=== æ­¥éª¤3ï¼šæµ‹è¯•ä½ç½®ä¿¡é“ä¼°è®¡ ===")
        print("-" * 70)
        
        L_h = 8
        f_ref = list(self.f_coeffs.values())[0]
        
        for pos in self.test_positions:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè®¾å¤‡ä¼°è®¡è¯¥ä½ç½®çš„ä¿¡é“
            if len(self.all_data[pos]) > 0:
                y = self.all_data[pos][0]
                d = self.all_data[self.train_position][0]
                
                D_R = self.construct_D_R(d, self.K, self.M)
                N = D_R.shape[0]
                y_trunc = y[:N]
                
                try:
                    y_pred = D_R @ f_ref
                    if len(y_pred) >= L_h:
                        h_est = y_trunc[:L_h] / (y_pred[:L_h] + 1e-8)
                        h_est /= (np.linalg.norm(h_est) + 1e-8)
                    else:
                        h_est = np.zeros(L_h, dtype=complex)
                        h_est[0] = 1.0
                except:
                    h_est = np.zeros(L_h, dtype=complex)
                    h_est[0] = 1.0
                
                # åº”ç”¨åˆ°æ‰€æœ‰æµ‹è¯•è®¾å¤‡
                for dev_id in self.device_ids[pos]:
                    self.h_estimates[dev_id] = h_est
                
                print(f"  âœ“ {pos}: ä¿¡é“ä¼°è®¡å®Œæˆ")
        
        print("\nâœ“ ä¿¡é“ä¼°è®¡å®Œæˆ\n")

    def extract_features(self):
        """æå–ç‰¹å¾"""
        print("=== æ­¥éª¤4ï¼šç‰¹å¾æå– ===")
        print("-" * 70)
        
        for pos in self.positions:
            if pos not in self.all_data or len(self.all_data[pos]) == 0:
                continue
                
            features = []
            
            for dev_idx, dev_id in enumerate(self.device_ids[pos]):
                # è·å–PAç³»æ•°
                if dev_id in self.f_coeffs:
                    f = self.f_coeffs[dev_id]
                else:
                    f = list(self.f_coeffs.values())[0]
                
                # è·å–ä¿¡é“
                h = self.h_estimates.get(dev_id, np.array([1.0]))
                
                # é‡å¡‘ä¸ºçŸ©é˜µ
                f_mat = f.reshape(self.M+1, self.K+1)
                
                # 8ç»´ç‰¹å¾
                # 1-3: PAç³»æ•°ç‰¹å¾
                phi1 = np.abs(f_mat[:, 1].mean()) / (np.abs(f_mat[:, 2].mean()) + 1e-10)
                phi2 = np.abs(f_mat[0, :].sum()) / (np.abs(f_mat[-1, :].sum()) + 1e-10)
                
                E1 = np.sum(np.abs(f_mat[:, 1])**2)
                E2 = np.sum(np.abs(f_mat[:, 2])**2)
                E3 = np.sum(np.abs(f_mat[:, 3])**2)
                phi3 = E1 / (E1 + E2 + E3 + 1e-10)
                
                # 4-5: ä¿¡é“ç‰¹å¾
                phi4 = np.linalg.norm(h, 2)
                phi5 = np.max(np.abs(h))
                
                # 6-8: ä¿¡å·ç»Ÿè®¡ç‰¹å¾
                y = self.all_data[pos][dev_idx]
                phi6 = np.std(np.abs(y))
                phi7 = np.mean(np.abs(y)**2)
                phi8 = np.std(np.angle(f_mat.flatten()))
                
                features.append([phi1, phi2, phi3, phi4, phi5, phi6, phi7, phi8])
            
            self.features_all[pos] = np.array(features)
            print(f"  âœ“ {pos}: {len(features)} ä¸ªè®¾å¤‡, 8ç»´ç‰¹å¾")
        
        self._plot_features()
        print("\nâœ“ ç‰¹å¾æå–å®Œæˆ\n")

    def _plot_features(self):
        """å¯è§†åŒ–ç‰¹å¾åˆ†å¸ƒ"""
        print("  ç”Ÿæˆå¯è§†åŒ–: ç‰¹å¾åˆ†å¸ƒ (K=3)")
        
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        axes = axes.flatten()
        
        names = [
            'phi1: f1/f2 ratio', 'phi2: Memory effect', 'phi3: k=1 Energy',
            'phi4: Channel L2', 'phi5: Channel Peak', 'phi6: Signal Std',
            'phi7: Signal Power', 'phi8: Phase Std'
        ]
        
        for i in range(8):
            for pos in self.positions:
                if pos not in self.features_all:
                    continue
                feat = self.features_all[pos][:, i]
                axes[i].hist(feat, bins=15, alpha=0.6, label=pos, edgecolor='black')
            
            axes[i].set_xlabel('Value', fontsize=10, fontweight='bold')
            axes[i].set_ylabel('Count', fontsize=10, fontweight='bold')
            axes[i].set_title(f'{names[i]} (K={self.K})', fontsize=11, fontweight='bold')
            axes[i].legend(fontsize=9)
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('viz_features_k3.png', dpi=300, bbox_inches='tight')
        plt.close()

    def train_and_evaluate(self):
        """è®­ç»ƒå’Œè¯„ä¼°"""
        print("=== æ­¥éª¤5ï¼šè®­ç»ƒåˆ†ç±»å™¨ (1P: p1) ===")
        print("-" * 70)
        
        X_train = self.features_all[self.train_position]
        y_train = np.array(self.device_ids[self.train_position])
        
        print(f"è®­ç»ƒé›†: {len(X_train)} ä¸ªæ ·æœ¬")
        print(f"è®¾å¤‡æ•°: {len(np.unique(y_train))} ä¸ª")
        
        X_train_norm = self.scaler.fit_transform(X_train)
        self.classifier = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
        self.classifier.fit(X_train_norm, y_train)
        
        print("\nâœ“ è®­ç»ƒå®Œæˆ\n")
        
        print("=== æ­¥éª¤6ï¼šè¯„ä¼° (3P: p2/p3/p4) ===")
        print("-" * 70)
        
        results = {}
        for pos in self.test_positions:
            if pos not in self.features_all:
                continue
                
            X_test = self.features_all[pos]
            y_test = np.array(self.device_ids[pos])
            
            X_test_norm = self.scaler.transform(X_test)
            y_pred = self.classifier.predict(X_test_norm)
            
            acc = accuracy_score(y_test, y_pred) * 100
            cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))
            
            results[pos] = {'accuracy': acc, 'cm': cm, 'y_true': y_test, 'y_pred': y_pred}
            print(f"  {pos}: {acc:.2f}%")
        
        self._plot_results(results)
        
        avg = np.mean([r['accuracy'] for r in results.values()])
        print("\n" + "=" * 70)
        print("å®éªŒæ€»ç»“")
        print("=" * 70)
        print(f"å›ºå®šå‚æ•°: K={self.K}, M={self.M}")
        print(f"å¹³å‡å‡†ç¡®ç‡: {avg:.2f}%")
        for pos, r in results.items():
            print(f"  {pos}: {r['accuracy']:.2f}%")
        print("=" * 70)

    def _plot_results(self, results):
        """å¯è§†åŒ–ç»“æœ"""
        print("\n  ç”Ÿæˆå¯è§†åŒ–: å‡†ç¡®ç‡å’Œæ··æ·†çŸ©é˜µ (K=3)")
        
        # å‡†ç¡®ç‡
        fig = plt.figure(figsize=(10, 6))
        pos_list = list(results.keys())
        accs = [results[p]['accuracy'] for p in pos_list]
        
        bars = plt.bar(range(len(pos_list)), accs,
                      color=['#E63946', '#F4A261', '#2A9D8F'],
                      alpha=0.85, edgecolor='black', linewidth=1.5)
        
        plt.xlabel('Test Position', fontsize=13, fontweight='bold')
        plt.ylabel('Accuracy (%)', fontsize=13, fontweight='bold')
        plt.title(f'Cross-Position Recognition Accuracy (K={self.K}, M={self.M})\n' +
                 '1P Train: p1 -> 3P Test: p2/p3/p4',
                 fontsize=14, fontweight='bold')
        plt.xticks(range(len(pos_list)), pos_list, fontsize=12)
        plt.ylim([0, 105])
        plt.grid(True, alpha=0.3, axis='y')
        
        for i, (bar, acc) in enumerate(zip(bars, accs)):
            plt.text(i, acc + 2, f'{acc:.1f}%',
                    ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        avg = np.mean(accs)
        plt.axhline(y=avg, color='red', linestyle='--', linewidth=2,
                   label=f'Average: {avg:.2f}%', alpha=0.7)
        plt.legend(fontsize=11)
        plt.tight_layout()
        plt.savefig('viz_accuracy_k3.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # æ··æ·†çŸ©é˜µ
        fig, axes = plt.subplots(1, len(results), figsize=(7*len(results), 6))
        if len(results) == 1:
            axes = [axes]
        
        for idx, (pos, res) in enumerate(results.items()):
            cm = res['cm']
            cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-10)
            
            im = axes[idx].imshow(cm_norm, cmap='RdYlGn', vmin=0, vmax=1, aspect='auto')
            axes[idx].set_xlabel('Predicted Device ID', fontsize=11, fontweight='bold')
            axes[idx].set_ylabel('True Device ID', fontsize=11, fontweight='bold')
            axes[idx].set_title(f'{pos} - Confusion Matrix (Acc: {res["accuracy"]:.1f}%, K={self.K})',
                               fontsize=12, fontweight='bold')
            
            cbar = plt.colorbar(im, ax=axes[idx])
            cbar.set_label('Accuracy', fontsize=10)
            
            ids = np.unique(res['y_true'])
            axes[idx].set_xticks(range(len(ids)))
            axes[idx].set_yticks(range(len(ids)))
            axes[idx].set_xticklabels(ids, rotation=45, fontsize=8)
            axes[idx].set_yticklabels(ids, fontsize=8)
        
        plt.tight_layout()
        plt.savefig('viz_confusion_k3.png', dpi=300, bbox_inches='tight')
        plt.close()

    def run(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        start = time.time()
        
        self.load_data()
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½æ•°æ®
        if not self.all_data or self.train_position not in self.all_data:
            print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒæ•°æ® (p1ç›®å½•)")
            print("è¯·ç¡®ä¿ä»¥ä¸‹ç›®å½•å­˜åœ¨ä¸”åŒ…å«.matæ–‡ä»¶:")
            for pos in self.positions:
                print(f"  - {pos}/")
            return
        
        self.alternating_optimization()
        self.estimate_test_channels()
        self.extract_features()
        self.train_and_evaluate()
        
        print(f"\nâ±ï¸ æ€»è€—æ—¶: {time.time() - start:.2f} ç§’")
        print("\nâœ… æ‰€æœ‰å¯è§†åŒ–æ–‡ä»¶ (K=3):")
        print("  1. viz_optimization_k3.png - äº¤æ›¿ä¼˜åŒ–è¿‡ç¨‹")
        print("  2. viz_features_k3.png - ç‰¹å¾åˆ†å¸ƒ")
        print("  3. viz_accuracy_k3.png - å‡†ç¡®ç‡å¯¹æ¯”")
        print("  4. viz_confusion_k3.png - æ··æ·†çŸ©é˜µ")

if __name__ == "__main__":
    system = ImprovedRFF(K=3, M=8)
    system.run()

